{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f49cb4b-4c7b-4723-a2ac-3b5b1a95ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79945958-01a7-43a0-8dec-3b82d4bfc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name , society , price , area , areaWithType , bedRooms , bathRooms  = [],[],[],[],[],[],[]\n",
    "additionalRooms , address , floorNum , facing , agePossesion , nearbyLocation = [],[],[],[],[],[]\n",
    "description , furnishDetails , features , rating , propertyId ,links = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3acca35-bfc2-424f-a945-b7025c3eaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Prevents detection as bot\n",
    "options.add_argument(\"--start-maximized\")  # Opens browser in full screen\n",
    "#options.add_argument(\"--incognito\")  # Opens browser in Incognito mode\n",
    "options.add_argument(\"--disable-popup-blocking\")  # Prevents blocking of popups\n",
    "options.add_argument(\"--disable-infobars\")  # Removes 'Chrome is being controlled by automated test software'\n",
    "options.add_argument(\"--disable-gpu\")  # Reduces detection based on GPU usage\n",
    "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e2222e-9cfe-4b41-89aa-a4c2a59d5915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ns = Service(service = '/Users/sehajsukhleensingh/.wdm/drivers/chromedriver/mac64/133.0.6943.126/chromedriver-mac-arm64/chromedriver')\\ndriver = webdriver.Chrome(service = s,options = options )\\nactions = ActionChains(driver)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "s = Service(service = '/Users/sehajsukhleensingh/.wdm/drivers/chromedriver/mac64/133.0.6943.126/chromedriver-mac-arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service = s,options = options )\n",
    "actions = ActionChains(driver)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a126ab64-736b-498a-a1e8-4662df539d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npageNumber = 6\\nstart = pageNumber\\nend = 100\\nwhile start < end:\\n    driver.get(f\\'https://www.99acres.com/flats-in-gurgaon-ffid-page-{start}?search_type=QS&search_location=SH&verified=Y\\')\\n    time.sleep(1.5)\\n    old_height = driver.execute_script(\\'return document.body.scrollHeight\\')\\n    while True:\\n        \\n        driver.execute_script(\\'window.scrollTo(0,document.body.scrollHeight)\\')\\n        time.sleep(2)\\n        \\n        new_height = driver.execute_script(\\'return document.body.scrollHeight\\')\\n        if new_height == old_height:\\n            break\\n        old_height = new_height \\n    \\n    html = driver.page_source\\n    soup = bs(html,\\'lxml\\')\\n    containers = soup.find_all(\\'div\\',class_=\\'tupleNew__innerCont\\')\\n    \\n    for item in containers:\\n        try:\\n            link = item.find(\\'a\\', class_ = \\'tupleNew__propertyHeading ellipsis\\').get(\\'href\\')\\n            links.append(link)\\n            try:\\n                name.append(item.find(\\'h2\\',class_ = \\'tupleNew__propType\\').get_text(strip = True))\\n            except:\\n                name.append(np.nan)\\n            try:\\n                rating.append(item.find(\\'span\\',class_ = \\'tupleNew__locRatings\\').find(\\'span\\').get_text(strip = True))\\n            except:\\n                rating.append(np.nan)\\n        except:\\n            print(\"couldn\\'t find the link ...\")\\n    start += 1\\ndriver.quit()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pageNumber = 6\n",
    "start = pageNumber\n",
    "end = 100\n",
    "while start < end:\n",
    "    driver.get(f'https://www.99acres.com/flats-in-gurgaon-ffid-page-{start}?search_type=QS&search_location=SH&verified=Y')\n",
    "    time.sleep(1.5)\n",
    "    old_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        \n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "        time.sleep(2)\n",
    "        \n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        if new_height == old_height:\n",
    "            break\n",
    "        old_height = new_height \n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = bs(html,'lxml')\n",
    "    containers = soup.find_all('div',class_='tupleNew__innerCont')\n",
    "    \n",
    "    for item in containers:\n",
    "        try:\n",
    "            link = item.find('a', class_ = 'tupleNew__propertyHeading ellipsis').get('href')\n",
    "            links.append(link)\n",
    "            try:\n",
    "                name.append(item.find('h2',class_ = 'tupleNew__propType').get_text(strip = True))\n",
    "            except:\n",
    "                name.append(np.nan)\n",
    "            try:\n",
    "                rating.append(item.find('span',class_ = 'tupleNew__locRatings').find('span').get_text(strip = True))\n",
    "            except:\n",
    "                rating.append(np.nan)\n",
    "        except:\n",
    "            print(\"couldn't find the link ...\")\n",
    "    start += 1\n",
    "driver.quit()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49dbd994-ac02-4b57-b1b6-798d85a4ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(name),len(rating),len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e02566-098c-4c8e-9a58-613f9320e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = pd.DataFrame({'propertName':name,'links':links,'rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b383216-2ed9-496a-9e0a-d8ab589035aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt.to_csv('99acres-gurgaon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17efdbe-580b-4994-ab20-8da47dac0ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a332bbd0-7777-4340-9254-98e61fa25331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ns = Service(service = '/Users/sehajsukhleensingh/.wdm/drivers/chromedriver/mac64/133.0.6943.126/chromedriver-mac-arm64/chromedriver')\\ndriver = webdriver.Chrome(service = s,options = options )\\nactions = ActionChains(driver)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "s = Service(service = '/Users/sehajsukhleensingh/.wdm/drivers/chromedriver/mac64/133.0.6943.126/chromedriver-mac-arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service = s,options = options )\n",
    "actions = ActionChains(driver)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6ceb5b-37a2-40ed-80d5-01b63a9cd4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ni = -1\\nfor link in links:\\n    i += 1\\n    driver.get(link)\\n    old_height = driver.execute_script('return document.body.scrollHeight')\\n    while True:\\n        driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\\n        time.sleep(1.5)\\n        new_height = driver.execute_script('return document.body.scrollHeight')\\n        \\n        if old_height == new_height:\\n            break\\n        old_height = new_height\\n        \\n    html = driver.page_source\\n    soup = bs(html,'lxml')\\n    try:\\n        try:\\n            price.append(soup.find('span',id = 'pdPrice2').text)\\n        except:\\n            price.append(np.nan)\\n        try:\\n            society.append(soup.find('span',id = 'component__pdPropAddress').text.split(',')[0])\\n        except:\\n            society.append(np.nan)\\n        try:\\n            area.append(soup.find('span',id = 'superbuiltupArea_span').text)\\n        except:\\n            area.append(np.nan)\\n        try:\\n            areaWithType.append(soup.find('span',id = 'builtupArea_span').text)\\n        except:\\n            areaWithType.append(soup.find('span', id = 'carpetArea_span').text)\\n        try:\\n            facing.append(soup.find('span',id = 'facingLabel').text)\\n        except:\\n            facing.append(np.nan)\\n        try:\\n            floorNum.append(soup.find('span',id = 'floorNumLabel').text)\\n        except:\\n            floorNum.append(np.nan)\\n        try:\\n            agePossesion.append(soup.find('span',id = 'agePossessionLbl').text)\\n        except:\\n            agePossesion.append(np.nan)\\n        try:\\n            address.append(soup.find('div',id = 'component__details').text)\\n        except:\\n            address.append(np.nan)\\n        try:\\n            description.append(soup.find('span',id = 'description').text)\\n        except:\\n            description.append(np.nan)\\n        try:\\n            ul = soup.find_all('ul', id = 'features')\\n            furnishDetails.append([li.text for li in ul[0].find_all('li')])\\n        except:\\n            furnishDetails.append(np.nan)\\n        try:\\n            features.append([li.text for li in ul[1].find_all('li')])\\n        except:\\n            features.append(np.nan)\\n        try:\\n            bedRooms.append(soup.find('span',id = 'bedRoomNum').text)\\n        except:\\n            bedRooms.append(np.nan)\\n        try:\\n            bathRooms.append(soup.find('span',id = 'bathroomNum').text)\\n        except:\\n            bathRooms.append(np.nan)\\n        try:\\n            additionalRooms.append(soup.find('span',id = 'additionalRooms').text)\\n        except:\\n            additionalRooms.append(np.nan)\\n        try:\\n            spanlis = soup.find_all('span',class_ = 'NearByLocation__infoText')\\n            nearbyLocation.append([item.text for item in spanlis])\\n        except:\\n            nearbyLocation.append(np.nan)\\n        try:\\n            propertyId.append(soup.find('span',id = 'Prop_Id').text)\\n        except:\\n            propertyId.append(np.nan)\\n        print(f'scraped the page number {i}')\\n    except:\\n        society.append(np.nan)\\n        price.append(np.nan)\\n        area.append(np.nan)\\n        areaWithType.append(np.nan)\\n        bedRooms.append(np.nan)\\n        bathRooms.append(np.nan)\\n        additionalRooms.append(np.nan)\\n        address.append(np.nan)\\n        floorNum.append(np.nan)\\n        facing.append(np.nan)\\n        agePossesion.append(np.nan)\\n        nearbyLocation.append(np.nan)\\n        description.append(np.nan)\\n        furnishDetails.append(np.nan)\\n        features.append(np.nan)\\n        propertyId.append(np.nan)\\n        print('driver couldnt connect to link ... ')\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "i = -1\n",
    "for link in links:\n",
    "    i += 1\n",
    "    driver.get(link)\n",
    "    old_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "        time.sleep(1.5)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if old_height == new_height:\n",
    "            break\n",
    "        old_height = new_height\n",
    "        \n",
    "    html = driver.page_source\n",
    "    soup = bs(html,'lxml')\n",
    "    try:\n",
    "        try:\n",
    "            price.append(soup.find('span',id = 'pdPrice2').text)\n",
    "        except:\n",
    "            price.append(np.nan)\n",
    "        try:\n",
    "            society.append(soup.find('span',id = 'component__pdPropAddress').text.split(',')[0])\n",
    "        except:\n",
    "            society.append(np.nan)\n",
    "        try:\n",
    "            area.append(soup.find('span',id = 'superbuiltupArea_span').text)\n",
    "        except:\n",
    "            area.append(np.nan)\n",
    "        try:\n",
    "            areaWithType.append(soup.find('span',id = 'builtupArea_span').text)\n",
    "        except:\n",
    "            areaWithType.append(soup.find('span', id = 'carpetArea_span').text)\n",
    "        try:\n",
    "            facing.append(soup.find('span',id = 'facingLabel').text)\n",
    "        except:\n",
    "            facing.append(np.nan)\n",
    "        try:\n",
    "            floorNum.append(soup.find('span',id = 'floorNumLabel').text)\n",
    "        except:\n",
    "            floorNum.append(np.nan)\n",
    "        try:\n",
    "            agePossesion.append(soup.find('span',id = 'agePossessionLbl').text)\n",
    "        except:\n",
    "            agePossesion.append(np.nan)\n",
    "        try:\n",
    "            address.append(soup.find('div',id = 'component__details').text)\n",
    "        except:\n",
    "            address.append(np.nan)\n",
    "        try:\n",
    "            description.append(soup.find('span',id = 'description').text)\n",
    "        except:\n",
    "            description.append(np.nan)\n",
    "        try:\n",
    "            ul = soup.find_all('ul', id = 'features')\n",
    "            furnishDetails.append([li.text for li in ul[0].find_all('li')])\n",
    "        except:\n",
    "            furnishDetails.append(np.nan)\n",
    "        try:\n",
    "            features.append([li.text for li in ul[1].find_all('li')])\n",
    "        except:\n",
    "            features.append(np.nan)\n",
    "        try:\n",
    "            bedRooms.append(soup.find('span',id = 'bedRoomNum').text)\n",
    "        except:\n",
    "            bedRooms.append(np.nan)\n",
    "        try:\n",
    "            bathRooms.append(soup.find('span',id = 'bathroomNum').text)\n",
    "        except:\n",
    "            bathRooms.append(np.nan)\n",
    "        try:\n",
    "            additionalRooms.append(soup.find('span',id = 'additionalRooms').text)\n",
    "        except:\n",
    "            additionalRooms.append(np.nan)\n",
    "        try:\n",
    "            spanlis = soup.find_all('span',class_ = 'NearByLocation__infoText')\n",
    "            nearbyLocation.append([item.text for item in spanlis])\n",
    "        except:\n",
    "            nearbyLocation.append(np.nan)\n",
    "        try:\n",
    "            propertyId.append(soup.find('span',id = 'Prop_Id').text)\n",
    "        except:\n",
    "            propertyId.append(np.nan)\n",
    "        print(f'scraped the page number {i}')\n",
    "    except:\n",
    "        society.append(np.nan)\n",
    "        price.append(np.nan)\n",
    "        area.append(np.nan)\n",
    "        areaWithType.append(np.nan)\n",
    "        bedRooms.append(np.nan)\n",
    "        bathRooms.append(np.nan)\n",
    "        additionalRooms.append(np.nan)\n",
    "        address.append(np.nan)\n",
    "        floorNum.append(np.nan)\n",
    "        facing.append(np.nan)\n",
    "        agePossesion.append(np.nan)\n",
    "        nearbyLocation.append(np.nan)\n",
    "        description.append(np.nan)\n",
    "        furnishDetails.append(np.nan)\n",
    "        features.append(np.nan)\n",
    "        propertyId.append(np.nan)\n",
    "        print('driver couldnt connect to link ... ')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
